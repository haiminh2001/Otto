{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0:clicks 1:carts 2:orders\n",
    "type_weight = {0:1, 1:10, 2:3}\n",
    "type_weight_multipliers = type_weight\n",
    "\n",
    "top = 40\n",
    "NUM_AIDS = 20000000\n",
    "\n",
    "VER = 1\n",
    "DIR = f'/home/anhphantq/vdb/covisit_ver{VER}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/home/anhphantq/vdb/covisit_ver1'\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "try:\n",
    "    os.mkdir(DIR)\n",
    "    \n",
    "    os.mkdir(DIR + '/splitted')\n",
    "    os.mkdir(DIR + '/lb')\n",
    "except OSError as error:\n",
    "    print(error)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1661119199, 1659304800)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "\n",
    "train_df = pd.read_parquet('/home/anhphantq/otto/splitted_data/train.parquet')\n",
    "test_df = pd.read_parquet('/home/anhphantq/otto/splitted_data/test.parquet')\n",
    "all_df = pd.concat((train_df, test_df))\n",
    "MAX_TS = train_df.ts.max()\n",
    "MIN_TS = train_df.ts.min()\n",
    "MAX_TS, MIN_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1661723999, 1659909600)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_parquet('/home/anhphantq/otto/data/train.parquet')\n",
    "\n",
    "#remove 1 week from train df LB to retain distribution \n",
    "import numpy as np\n",
    "min_ts = train_df.ts.values.min()\n",
    "old_index = np.argwhere(train_df.ts.values - min_ts < 3600 * 24 * 7)\n",
    "train_df = train_df.drop(old_index.flatten())\n",
    "test_df = pd.read_parquet('/home/anhphantq/otto/data/test.parquet')\n",
    "all_df = pd.concat((train_df, test_df))\n",
    "MAX_TS = train_df.ts.max()\n",
    "MIN_TS = train_df.ts.min()\n",
    "MAX_TS, MIN_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_covisit(df):    \n",
    "    df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "\n",
    "    # USE TAIL OF SESSION\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['n'] = df.groupby('session').cumcount()\n",
    "    df = df.loc[df.n<30].drop('n',axis=1)\n",
    "\n",
    "    # CREATE PAIRS\n",
    "    df = df.merge(df,on='session')\n",
    "    df = df.loc[ ((df.ts_x - df.ts_y).abs()< 1 * 60 * 60) & (df.aid_x != df.aid_y) ]\n",
    "\n",
    "\n",
    "    # ASSIGN WEIGHTS\n",
    "    df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y', 'type_y'])\n",
    "    df['wgt'] = df.type_y.map(type_weight)\n",
    "    df = df[['aid_x','aid_y','wgt']]\n",
    "    df.wgt = df.wgt.astype('float32')\n",
    "    \n",
    "    \n",
    "    df = df.groupby(['aid_x','aid_y']).wgt.sum().reset_index().sort_values(['aid_x','wgt'],ascending=[True,False]).reset_index(drop = True)\n",
    "    df['n'] = df.groupby('aid_x').aid_y.cumcount()\n",
    "    #SAVE TOP \n",
    "    df = df.loc[df.n < top].drop('n', axis = 1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "step = all_df.shape[0] // 64\n",
    "start = [i * step for i in range(64)]\n",
    "end = [i + step for i in start]\n",
    "end[-1] = all_df.shape[0] \n",
    "\n",
    "batches = [all_df.iloc[start[i]: end[i]].copy() for i in range(len(start))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.8 s, sys: 41.3 s, total: 1min 23s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#splitted\n",
    "\n",
    "import multiprocessing\n",
    "with multiprocessing.Pool(64) as pool:\n",
    "  pd.concat(pool.map(create_covisit, batches, chunksize = 1)).to_parquet(DIR + f'/splitted/covisit')\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create top clicks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:28<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create top buy2buy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:15<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create top clicks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:15<00:00,  4.04it/s]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#splitted\n",
    "\n",
    "import multiprocessing\n",
    "with multiprocessing.Pool(64) as pool:\n",
    "  pd.concat(pool.map(create_covisit, batches, chunksize = 1)).to_parquet(DIR + f'/lb/covisit')\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECENT covisit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def create_recent_7_days(df):\n",
    "    df['date'] = pd.to_datetime(df.ts * 1e9)#7 recent days\n",
    "    df['dayofyear'] = df.date.dt.dayofyear\n",
    "\n",
    "    dayofyear_max = df['dayofyear'].max()\n",
    "    dayofyear_min = dayofyear_max - 6\n",
    "\n",
    "    df = df.loc[(df.dayofyear >= dayofyear_min) & (df.dayofyear <= dayofyear_max)]\n",
    "    result = []\n",
    "    for i in range(dayofyear_min, dayofyear_max + 1):\n",
    "        result.append(create_covisit(df.loc[df.dayofyear == i]))\n",
    "\n",
    "    return result\n",
    "        \n",
    "   \n",
    "def pqt_to_dict(df, i, f):\n",
    "    df['covistation_list'] = list(zip(df.aid_y, df.wgt))\n",
    "    \n",
    "    df = df.groupby('aid_x').covistation_list.apply(list)\n",
    "    disk_df = np.memmap(f'{f}/covisit{i}.array', dtype='object', mode='w+', shape=NUM_AIDS)\n",
    "    disk_df[df.index.values] = df.values\n",
    "    del df \n",
    "    return disk_df\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "step = train_df.shape[0] // 64\n",
    "start = [i * step for i in range(64)]\n",
    "end = [i + step for i in start]\n",
    "end[-1] = train_df.shape[0] \n",
    "\n",
    "batches = [train_df.iloc[start[i]: end[i]].copy() for i in range(len(start))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.1 s, sys: 30.7 s, total: 1min 3s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#splitted\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "with multiprocessing.Pool(64) as pool:\n",
    "  result = pool.map(create_recent_7_days, batches, chunksize = 1)\n",
    "  for i in range(7):  \n",
    "      pqt_to_dict(pd.concat([r[i] for r in result]), i, '/home/anhphantq/otto/splitted')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.7 s, sys: 26.8 s, total: 1min\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#lb\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "with multiprocessing.Pool(64) as pool:\n",
    "  result = pool.map(create_recent_7_days, batches, chunksize = 1)\n",
    "  for i in range(7):  \n",
    "      pqt_to_dict(pd.concat([r[i] for r in result]), i, '/home/anhphantq/otto/lb')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
