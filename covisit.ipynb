{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0:clicks 1:carts 2:orders\n",
    "type_weight = {0:0.5,\n",
    "               1:9,\n",
    "               2:0.5}\n",
    "type_weight_multipliers = type_weight\n",
    "\n",
    "# Use top X for clicks, carts and orders Top何位までを使うか\n",
    "clicks_th = 40 \n",
    "carts_th  = 100 \n",
    "orders_th = 100\n",
    "\n",
    "VER = 1\n",
    "DIR = f'/home/anhphantq/vdb/covisit_ver_{VER}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/home/anhphantq/vdb/covist_ver_1'\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "try:\n",
    "    os.mkdir(DIR)\n",
    "    \n",
    "    os.mkdir(DIR + '/splitted')\n",
    "    os.mkdir(DIR + '/lb')\n",
    "except OSError as error:\n",
    "    print(error)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.13 s, sys: 4.9 s, total: 10 s\n",
      "Wall time: 4.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1661119199, 1659304800)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "\n",
    "train_df = pd.read_parquet('/home/anhphantq/otto/splitted_data/train.parquet')\n",
    "MAX_TS = train_df.ts.max()\n",
    "MIN_TS = train_df.ts.min()\n",
    "MAX_TS, MIN_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163555218,\n",
       " 216716096,\n",
       " 53160878,\n",
       " 1839558,\n",
       " 1855603,\n",
       " 16045,\n",
       " 1661723999,\n",
       " 1659909600)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_parquet('/home/anhphantq/otto/data/train.parquet')\n",
    "\n",
    "#remove 1 week from train df LB to retain distribution \n",
    "import numpy as np\n",
    "min_ts = train_df.ts.values.min()\n",
    "old_index = np.argwhere(train_df.ts.values - min_ts < 3600 * 24 * 7)\n",
    "old_shape = train_df.shape[0]\n",
    "old_num_aid = len(np.unique(train_df.aid))\n",
    "train_df = train_df.drop(old_index.flatten())\n",
    "num_aid = len(np.unique(train_df.aid))\n",
    "MAX_TS = train_df.ts.max()\n",
    "MIN_TS = train_df.ts.min()\n",
    "train_df.shape[0], old_shape,  old_shape - train_df.shape[0], num_aid, old_num_aid, old_num_aid - num_aid, MAX_TS, MIN_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cart_order(args):\n",
    "    df, batch_id = args[0], args[1]\n",
    "    df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "\n",
    "# USE TAIL OF SESSION\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['n'] = df.groupby('session').cumcount()\n",
    "    df = df.loc[df.n<30].drop('n',axis=1)\n",
    "\n",
    "    # CREATE PAIRS\n",
    "    df = df.merge(df,on='session')\n",
    "    df = df.loc[ ((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n",
    "\n",
    "\n",
    "    # ASSIGN WEIGHTS\n",
    "    df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y', 'type_y'])\n",
    "    df['wgt'] = df.type_y.map(type_weight)\n",
    "    df = df[['aid_x','aid_y','wgt']]\n",
    "    df.wgt = df.wgt.astype('float32')\n",
    "    df = df.groupby(['aid_x','aid_y']).wgt.sum().reset_index().sort_values(['aid_x','wgt'],ascending=[True,False]).reset_index(drop = True)\n",
    "    df['n'] = df.groupby('aid_x').aid_y.cumcount()\n",
    "    #SAVE TOP 100\n",
    "    df = df.loc[df.n < carts_th].drop('n', axis = 1)\n",
    "    return df, batch_id\n",
    "\n",
    "\n",
    "def create_buy2buy(args):\n",
    "    df, batch_id = args[0], args[1]\n",
    "    \n",
    "    \n",
    "    df = df.loc[df['type'].isin([1,2])]\n",
    "    df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "\n",
    "    # USE TAIL OF SESSION\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['n'] = df.groupby('session').cumcount()\n",
    "    df = df.loc[df.n<30].drop('n',axis=1)\n",
    "\n",
    "    # CREATE PAIRS\n",
    "    df = df.merge(df,on='session')\n",
    "    df = df.loc[ ((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n",
    "\n",
    "\n",
    "    # ASSIGN WEIGHTS\n",
    "    df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y', 'type_y'])\n",
    "    df['wgt'] = df.type_y.map(type_weight)\n",
    "    df = df[['aid_x','aid_y','wgt']]\n",
    "    df.wgt = df.wgt.astype('float32')\n",
    "    df = df.groupby(['aid_x','aid_y']).wgt.sum().reset_index().sort_values(['aid_x','wgt'],ascending=[True,False]).reset_index(drop = True)\n",
    "    df['n'] = df.groupby('aid_x').aid_y.cumcount()\n",
    "    #SAVE TOP 100\n",
    "    df = df.loc[df.n < orders_th].drop('n', axis = 1)\n",
    "    return df, batch_id\n",
    "\n",
    "def create_click(args):\n",
    "    df, batch_id = args[0], args[1]\n",
    "    \n",
    "    \n",
    "    df = df.loc[df['type'].isin([1,2])]\n",
    "    df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "\n",
    "    # USE TAIL OF SESSION\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['n'] = df.groupby('session').cumcount()\n",
    "    df = df.loc[df.n<30].drop('n',axis=1)\n",
    "\n",
    "    # CREATE PAIRS\n",
    "    df = df.merge(df,on='session')\n",
    "    df = df.loc[ ((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n",
    "\n",
    "\n",
    "    # ASSIGN WEIGHTS\n",
    "    df = df[['session', 'aid_x', 'aid_y','ts_x']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "    df['wgt'] = 1 + 3*(df.ts_x - MIN_TS)/(MAX_TS-MIN_TS)\n",
    "    \n",
    "    df = df[['aid_x','aid_y','wgt']]\n",
    "    df.wgt = df.wgt.astype('float32')\n",
    "    df = df.groupby(['aid_x','aid_y']).wgt.sum().reset_index().sort_values(['aid_x','wgt'],ascending=[True,False]).reset_index(drop = True)\n",
    "    df['n'] = df.groupby('aid_x').aid_y.cumcount()\n",
    "    #SAVE TOP 100\n",
    "    df = df.loc[df.n < clicks_th].drop('n', axis = 1)\n",
    "    return df, batch_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "step = train_df.shape[0] // 64\n",
    "start = [i * step for i in range(64)]\n",
    "end = [i + step for i in start]\n",
    "end[-1] = train_df.shape[0] \n",
    "\n",
    "batches = [train_df.iloc[start[i]: end[i]].copy() for i in range(len(start))]\n",
    "batch_names = [i for i in range(len(batches))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create top clicks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:28<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create top buy2buy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:11<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create top clicks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:12<00:00,  5.27it/s]\n"
     ]
    }
   ],
   "source": [
    "#splitted\n",
    "import multiprocessing\n",
    "print('create top clicks')\n",
    "with multiprocessing.Pool(64) as pool:\n",
    "  for rs, batch_id in tqdm(pool.imap_unordered(create_cart_order,  tuple(zip(batches, batch_names)), chunksize = 1), total = len(batches)):\n",
    "    rs.to_parquet(DIR + f'/splitted/top_carts_orders_frag_{batch_id}', index = True)\n",
    "  \n",
    "print('create top buy2buy')\n",
    "with multiprocessing.Pool(64) as pool:\n",
    "  for rs, batch_id in tqdm(pool.imap_unordered(create_buy2buy,  tuple(zip(batches, batch_names)), chunksize = 1), total = len(batches)):\n",
    "    rs.to_parquet(DIR + f'/splitted/top_buy2buy_frag_{batch_id}', index = True)\n",
    "\n",
    "print('create top clicks')\n",
    "with multiprocessing.Pool(64) as pool:\n",
    "  for rs, batch_id in tqdm(pool.imap_unordered(create_click,  tuple(zip(batches, batch_names)), chunksize = 1), total = len(batches)):\n",
    "    rs.to_parquet(DIR + f'/splitted/top_click_frag_{batch_id}', index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create top clicks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:28<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create top buy2buy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:15<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create top clicks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:15<00:00,  4.04it/s]\n"
     ]
    }
   ],
   "source": [
    "#lb\n",
    "import multiprocessing\n",
    "print('create top clicks')\n",
    "with multiprocessing.Pool(64) as pool:\n",
    "  for rs, batch_id in tqdm(pool.imap_unordered(create_cart_order,  tuple(zip(batches, batch_names)), chunksize = 1), total = len(batches)):\n",
    "    rs.to_parquet(DIR + f'/lb/top_carts_orders_frag_{batch_id}', index = True)\n",
    "  \n",
    "print('create top buy2buy')\n",
    "with multiprocessing.Pool(64) as pool:\n",
    "  for rs, batch_id in tqdm(pool.imap_unordered(create_buy2buy,  tuple(zip(batches, batch_names)), chunksize = 1), total = len(batches)):\n",
    "    rs.to_parquet(DIR + f'/lb/top_buy2buy_frag_{batch_id}', index = True)\n",
    "\n",
    "print('create top clicks')\n",
    "with multiprocessing.Pool(64) as pool:\n",
    "  for rs, batch_id in tqdm(pool.imap_unordered(create_click,  tuple(zip(batches, batch_names)), chunksize = 1), total = len(batches)):\n",
    "    rs.to_parquet(DIR + f'/lb/top_click_frag_{batch_id}', index = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
